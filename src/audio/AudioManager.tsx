import React, { createContext, useContext, useRef, useState, useEffect } from 'react';
import { audioUnlockService } from '../services/AudioUnlockService';

export interface AudioTrack {
  id: string;
  name: string;
  url: string;
  duration?: number;
}

export interface AudioManagerContextType {
  currentTrack: AudioTrack | null;
  isPlaying: boolean;
  volume: number;
  progress: number;
  isMuted: boolean;
  tracks: AudioTrack[];
  play: (trackId: string) => Promise<void>;
  pause: () => void;
  toggleMute: () => void;
  setVolume: (volume: number) => void;
  seek: (progress: number) => void;
  loadTracks: (tracks: AudioTrack[]) => void;
  unlockAndPlay: (trackId: string) => Promise<boolean>;
  fadeInPlay: (trackId: string, duration?: number) => Promise<void>;
}

const AudioManagerContext = createContext<AudioManagerContextType | null>(null);

export const useAudioManager = () => {
  const context = useContext(AudioManagerContext);
  if (!context) {
    throw new Error('useAudioManager must be used within AudioManagerProvider');
  }
  return context;
};

export const AudioManagerProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [currentTrack, setCurrentTrack] = useState<AudioTrack | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [volume, setVolumeState] = useState(0.3);
  const [isMuted, setIsMuted] = useState(false);
  const [progress, setProgress] = useState(0);

  // ä½¿ç”¨æµ‹è¯•éŸ³é¢‘é“¾æ¥ï¼ˆé›¨å£°ç™½å™ªéŸ³ï¼‰å’Œæœ¬åœ°éŸ³é¢‘æ–‡ä»¶ä½œä¸ºå¤‡ç”¨
  const [tracks, setTracks] = useState<AudioTrack[]>([
    {
      id: 'rain-ambient',
      name: 'é›¨å£°ç™½å™ªéŸ³',
      url: 'https://actions.google.com/sounds/v1/weather/rain_heavy_loud.ogg',
    },
    {
      id: 'soft-piano',
      name: 'å†¥æƒ³é’¢ç´æ›²',
      url: '/audio/piano-meditation-1.mp3',
    },
    {
      id: 'sleep-music',
      name: 'ç¡çœ é’¢ç´æ›²',
      url: '/audio/piano-sleep-1.mp3',
    },
    {
      id: 'nature-sounds',
      name: 'é›¨å£°ç™½å™ªéŸ³',
      url: 'https://actions.google.com/sounds/v1/weather/rain_heavy_loud.ogg',
    },
    {
      id: 'meditation',
      name: 'å†¥æƒ³é’¢ç´æ›²',
      url: '/audio/piano-meditation-1.mp3',
    },
    {
      id: 'relaxing-nature',
      name: 'ç¡çœ é’¢ç´æ›²',
      url: '/audio/piano-sleep-1.mp3',
    }
  ]);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      audioRef.current = new Audio();
      audioRef.current.preload = 'auto';
      // è®¾ç½®åˆå§‹éŸ³é‡ä¸º 0.3ï¼ˆä¸è¦å¤ªå¤§å£°ï¼‰
      audioRef.current.volume = 0.3;
      // è®¾ç½®å¾ªç¯æ’­æ”¾ï¼ˆé€‚åˆç™½å™ªéŸ³å’Œè½»éŸ³ä¹ï¼‰
      audioRef.current.loop = true;

      const audio = audioRef.current;

      const updateTime = () => {
        if (audio.duration) {
          setProgress((audio.currentTime / audio.duration) * 100);
        }
      };

      const handleEnded = () => {
        // å¦‚æœè®¾ç½®äº†å¾ªç¯ï¼Œended äº‹ä»¶ä¸ä¼šè§¦å‘
        // ä½†ä¸ºäº†å…¼å®¹æ€§ï¼Œä»ç„¶å¤„ç†
        if (!audio.loop) {
          setIsPlaying(false);
          setProgress(0);
        }
      };

      const handleError = (e: any) => {
        console.error('éŸ³é¢‘å…ƒç´ é”™è¯¯:', e);
        setIsPlaying(false);
      };

      audio.addEventListener('timeupdate', updateTime);
      audio.addEventListener('ended', handleEnded);
      audio.addEventListener('error', handleError);

      return () => {
        audio.removeEventListener('timeupdate', updateTime);
        audio.removeEventListener('ended', handleEnded);
        audio.removeEventListener('error', handleError);
      };
    }
  }, []);

  useEffect(() => {
    if (audioRef.current) {
      audioRef.current.volume = volume;
    }
  }, [volume]);

  const play = async (trackId: string) => {
    const track = tracks.find(t => t.id === trackId);
    if (!track || !audioRef.current) {
      console.warn('âŒ æ‰¾ä¸åˆ°éŸ³é¢‘è½¨é“æˆ–éŸ³é¢‘å…ƒç´ æœªåˆå§‹åŒ–');
      return;
    }

    // å¦‚æœå·²ç»åœ¨æ’­æ”¾åŒä¸€ä¸ªéŸ³é¢‘ï¼Œç›´æ¥è¿”å›
    if (currentTrack && currentTrack.id === trackId && isPlaying) {
      console.log('âœ… éŸ³é¢‘å·²åœ¨æ’­æ”¾ï¼Œæ— éœ€é‡æ–°åŠ è½½:', track.name);
      return;
    }

    console.log('ğŸµ æ’­æ”¾éŸ³é¢‘:', track.name, track.url);

    try {
      // å…ˆè§£é”éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼ˆå¤„ç†æµè§ˆå™¨è‡ªåŠ¨æ’­æ”¾ç­–ç•¥ï¼‰
      await audioUnlockService.unlockAudio();

      // å¦‚æœå½“å‰æ­£åœ¨æ’­æ”¾å…¶ä»–éŸ³é¢‘ï¼Œå…ˆæš‚åœ
      if (isPlaying && currentTrack && currentTrack.id !== trackId) {
        audioRef.current.pause();
      }

      // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è®¾ç½®éŸ³é¢‘æºï¼ˆé€šè¿‡æ¯”è¾ƒ track ID è€Œä¸æ˜¯ URLï¼Œå› ä¸º URL å¯èƒ½æ ¼å¼ä¸åŒï¼‰
      const needsReload = !currentTrack || currentTrack.id !== trackId;
      
      if (needsReload) {
        // è®¾ç½®éŸ³é¢‘æº
        audioRef.current.src = track.url;
        audioRef.current.crossOrigin = 'anonymous';
        // ç¡®ä¿å¾ªç¯æ’­æ”¾ï¼ˆé€‚åˆç™½å™ªéŸ³å’Œè½»éŸ³ä¹ï¼‰
        audioRef.current.loop = true;
        setCurrentTrack(track);
        setProgress(0);

        // åŠ è½½éŸ³é¢‘
        audioRef.current.load();

        // ç­‰å¾…éŸ³é¢‘åŠ è½½å®Œæˆ
        await new Promise<void>((resolve, reject) => {
          if (!audioRef.current) {
            reject(new Error('éŸ³é¢‘å…ƒç´ ä¸å­˜åœ¨'));
            return;
          }

          const audio = audioRef.current!;

          const handleCanPlay = () => {
            audio.removeEventListener('canplay', handleCanPlay);
            audio.removeEventListener('error', handleError);
            resolve();
          };

          const handleError = (e: any) => {
            audio.removeEventListener('canplay', handleCanPlay);
            audio.removeEventListener('error', handleError);
            reject(new Error(`éŸ³é¢‘åŠ è½½å¤±è´¥: ${audio.error?.message || 'æœªçŸ¥é”™è¯¯'}`));
          };

          // å¦‚æœå·²ç»å¯ä»¥æ’­æ”¾ï¼Œç›´æ¥ resolve
          if (audio.readyState >= 2) {
            resolve();
            return;
          }

          audio.addEventListener('canplay', handleCanPlay);
          audio.addEventListener('error', handleError);

          // è®¾ç½®è¶…æ—¶ï¼ˆ5ç§’ï¼‰
          setTimeout(() => {
            audio.removeEventListener('canplay', handleCanPlay);
            audio.removeEventListener('error', handleError);
            reject(new Error('éŸ³é¢‘åŠ è½½è¶…æ—¶'));
          }, 5000);
        });
      } else {
        // å¦‚æœéŸ³é¢‘æºç›¸åŒï¼Œåªéœ€è¦æ›´æ–°å½“å‰è½¨é“ä¿¡æ¯
        setCurrentTrack(track);
        // å¦‚æœéŸ³é¢‘å·²æš‚åœï¼Œç¡®ä¿å®ƒèƒ½ç»§ç»­æ’­æ”¾ï¼ˆä½†ä¸éœ€è¦ç­‰å¾…åŠ è½½ï¼‰
        if (audioRef.current.paused) {
          // éŸ³é¢‘å·²åŠ è½½ï¼Œç›´æ¥å°è¯•æ’­æ”¾
          console.log('âœ… æ¢å¤æ’­æ”¾å·²åŠ è½½çš„éŸ³é¢‘');
        }
      }

      // æ’­æ”¾éŸ³é¢‘ - æ˜ç¡®è°ƒç”¨ play() å¹¶å¤„ç† promise rejection
      try {
        const playPromise = audioRef.current.play();
        
        if (playPromise !== undefined) {
          await playPromise;
          console.log('âœ… éŸ³é¢‘æ’­æ”¾æˆåŠŸ');
          setIsPlaying(true);
        } else {
          // å¦‚æœæ²¡æœ‰è¿”å› promiseï¼Œç›´æ¥è®¾ç½®ä¸ºæ’­æ”¾çŠ¶æ€
          setIsPlaying(true);
        }
      } catch (playError: any) {
        // å¤„ç†æ’­æ”¾å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æµè§ˆå™¨è‡ªåŠ¨æ’­æ”¾ç­–ç•¥é™åˆ¶ï¼‰
        console.warn('âš ï¸ éŸ³é¢‘æ’­æ”¾è¢«é˜»æ­¢:', playError.name, playError.message);
        setIsPlaying(false);
        
        // å¦‚æœæ˜¯ NotAllowedErrorï¼Œè¯´æ˜éœ€è¦ç”¨æˆ·äº¤äº’
        if (playError.name === 'NotAllowedError') {
          console.warn('ğŸ’¡ æç¤ºï¼šéœ€è¦ç”¨æˆ·äº¤äº’æ‰èƒ½æ’­æ”¾éŸ³é¢‘');
        }
        
        // é‡æ–°æŠ›å‡ºé”™è¯¯ï¼Œè®©è°ƒç”¨è€…çŸ¥é“æ’­æ”¾å¤±è´¥
        throw playError;
      }
    } catch (error: any) {
      console.error('âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error);
      console.error('âŒ é”™è¯¯åç§°:', error.name);
      console.error('âŒ é”™è¯¯æ¶ˆæ¯:', error.message);
      setIsPlaying(false);
      
      // ä½¿ç”¨æ›´å‹å¥½çš„é”™è¯¯æç¤ºï¼ˆä¸é˜»å¡ç”¨æˆ·ï¼‰
      const errorMessage = error.message || 'éŸ³é¢‘æ’­æ”¾å¤±è´¥';
      console.warn('éŸ³é¢‘æ’­æ”¾é”™è¯¯:', errorMessage);
      
      // å°è¯•ä½¿ç”¨å¤‡ç”¨éŸ³é¢‘æˆ–é™é»˜å¤±è´¥ï¼ˆä¸æ˜¾ç¤º alertï¼‰
      // å¦‚æœç”¨æˆ·éœ€è¦ï¼Œå¯ä»¥åœ¨ UI ä¸Šæ˜¾ç¤ºä¸€ä¸ªéé˜»å¡çš„æç¤º
    }
  };

  // è§£é”å¹¶æ’­æ”¾éŸ³é¢‘
  const unlockAndPlay = async (trackId: string): Promise<boolean> => {
    try {
      await play(trackId);
      return true;
    } catch (error) {
      console.error('Error in unlockAndPlay:', error);
      return false;
    }
  };

  // éŸ³é‡æ¸å…¥æ’­æ”¾
  const fadeInPlay = async (trackId: string, duration: number = 2000): Promise<void> => {
    try {
      // å…ˆæ­£å¸¸æ’­æ”¾
      await play(trackId);
      
      if (!audioRef.current) return;

      // ç„¶åå®ç°æ¸å…¥æ•ˆæœ
      const audio = audioRef.current;
      const targetVolume = volume;
      const steps = 60;
      const stepDuration = duration / steps;
      let currentStep = 0;

      audio.volume = 0;

      const fadeInterval = setInterval(() => {
        currentStep++;
        const progress = currentStep / steps;
        audio.volume = targetVolume * progress;

        if (currentStep >= steps) {
          clearInterval(fadeInterval);
          audio.volume = targetVolume;
        }
      }, stepDuration);
    } catch (error) {
      console.error('Error in fadeInPlay:', error);
    }
  };

  const pause = () => {
    if (audioRef.current) {
      audioRef.current.pause();
      setIsPlaying(false);
    }
  };

  const toggleMute = () => {
    if (audioRef.current) {
      const newMutedState = !isMuted;
      audioRef.current.muted = newMutedState;
      setIsMuted(newMutedState);
    }
  };

  const setVolume = (newVolume: number) => {
    setVolumeState(newVolume);
  };

  const seek = (newProgress: number) => {
    if (audioRef.current && audioRef.current.duration) {
      const time = (newProgress / 100) * audioRef.current.duration;
      audioRef.current.currentTime = time;
      setProgress(newProgress);
    }
  };

  const loadTracks = (newTracks: AudioTrack[]) => {
    setTracks(newTracks);
  };

  const value: AudioManagerContextType = {
    currentTrack,
    isPlaying,
    volume,
    progress,
    isMuted,
    tracks,
    play,
    pause,
    toggleMute,
    setVolume,
    seek,
    loadTracks,
    unlockAndPlay,
    fadeInPlay,
  };

  return (
    <AudioManagerContext.Provider value={value}>
      {children}
    </AudioManagerContext.Provider>
  );
};